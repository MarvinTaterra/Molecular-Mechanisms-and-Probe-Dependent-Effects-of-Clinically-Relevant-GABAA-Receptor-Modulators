{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "def generate_plumed_input_manual(atom_mapping, output_dir=\"path/to/output\"):\n",
    "    \"\"\"\n",
    "    Generate PLUMED input using fully manual atom indices.\n",
    "    \n",
    "    Args:\n",
    "        atom_mapping (dict): {generic_number: atom_index}\n",
    "        output_dir (str): Where to save the PLUMED file\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plumed_file_path = os.path.join(output_dir, \"distances.dat\")\n",
    "    \n",
    "    lines = [\"# Define distances between relevant atom pairs\"]\n",
    "    counter = 0\n",
    "    for it, (gen1, gen2) in enumerate(itertools.combinations(sorted(atom_mapping.keys()), 2), start=1):\n",
    "        atom1_index = atom_mapping[gen1]\n",
    "        atom2_index = atom_mapping[gen2]\n",
    "        lines.append(f\"d{it}: DISTANCE ATOMS={atom1_index},{atom2_index}  # {gen1} - {gen2}\")\n",
    "        counter += 1\n",
    "\n",
    "    if counter > 0:\n",
    "        distances = [f\"d{i}\" for i in range(1, counter + 1)]\n",
    "        lines.extend([\n",
    "            \"# Print values every 12500 steps, every 25 ps\",\n",
    "            f\"PRINT FILE=distances STRIDE=12500 ARG={','.join(distances)}\"\n",
    "        ])\n",
    "\n",
    "    with open(plumed_file_path, \"w\") as f:\n",
    "        for line in lines:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    print(f\"PLUMED input file written to: {plumed_file_path}\")\n",
    "\n",
    "def parse_pdb_for_ca_mapping(pdb_path):\n",
    "    mapping = {}\n",
    "\n",
    "    with open(pdb_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line.startswith(\"ATOM\"):\n",
    "                continue\n",
    "\n",
    "            atom_name = line[12:16].strip()\n",
    "            res_name = line[17:20].strip()\n",
    "            chain_or_segid = line[72:76].strip()  \n",
    "            res_num = line[22:26].strip()\n",
    "            atom_num = int(line[6:11])\n",
    "\n",
    "            if atom_name == \"CA\":\n",
    "                key = f\"{chain_or_segid}_{res_name}{res_num}\"\n",
    "                mapping[key] = atom_num\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdb_file = \"path/to/step5_input.pdb\"  #for charmm gui step5_input.pdb\n",
    "    ca_mapping = parse_pdb_for_ca_mapping(pdb_file)\n",
    "    for k, v in ca_mapping.items():\n",
    "        print(f'\"{k}\": {v},')\n",
    "    generate_plumed_input_manual(ca_mapping)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "def parse_plumed_file(file_path):\n",
    "    \"\"\"\n",
    "    Parse a PLUMED distances.dat file and extract distance definitions.\n",
    "    \n",
    "    Returns:\n",
    "        list: [(d_number, atom1, atom2, label1, label2, full_line), ...]\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    other_lines = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Match lines like: d1: DISTANCE ATOMS=1234,5678  # LABEL1 - LABEL2 \n",
    "            match = re.match(r'd(\\d+):\\s*DISTANCE\\s+ATOMS=(\\d+),(\\d+)\\s*#\\s*(.+?)\\s*-\\s*(.+)', line)\n",
    "            if match:\n",
    "                d_num = int(match.group(1))\n",
    "                atom1 = int(match.group(2))\n",
    "                atom2 = int(match.group(3))\n",
    "                label1 = match.group(4).strip()\n",
    "                label2 = match.group(5).strip()\n",
    "                \n",
    "                distances.append((d_num, atom1, atom2, label1, label2, line))\n",
    "            else:\n",
    "                other_lines.append(line)\n",
    "    \n",
    "    return distances, other_lines\n",
    "\n",
    "def create_canonical_ordering(all_files_data):\n",
    "    \"\"\"\n",
    "    Create a canonical ordering of all unique pairs across all files.\n",
    "    Uses alphabetical sorting of label pairs.\n",
    "    \n",
    "    Args:\n",
    "        all_files_data: dict of {filename: (distances_list, other_lines)}\n",
    "    \n",
    "    Returns:\n",
    "        OrderedDict: {(label1, label2): new_d_number}\n",
    "    \"\"\"\n",
    "    # Collect all unique pairs\n",
    "    all_pairs = set()\n",
    "    \n",
    "    for distances, _ in all_files_data.values():\n",
    "        for _, atom1, atom2, label1, label2, _ in distances:\n",
    "            # Normalize the pair (alphabetically)\n",
    "            pair = tuple(sorted([label1, label2]))\n",
    "            all_pairs.add(pair)\n",
    "    \n",
    "    # Sort pairs alphabetically for consistent ordering\n",
    "    sorted_pairs = sorted(all_pairs)\n",
    "    \n",
    "    # Create mapping with new d-numbers\n",
    "    canonical_mapping = OrderedDict()\n",
    "    for i, pair in enumerate(sorted_pairs, start=1):\n",
    "        canonical_mapping[pair] = i\n",
    "    \n",
    "    return canonical_mapping\n",
    "\n",
    "def renumber_file(file_path, canonical_mapping, output_path=None):\n",
    "    \"\"\"\n",
    "    Renumber a PLUMED file according to canonical mapping.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to original file\n",
    "        canonical_mapping: OrderedDict mapping (label1, label2) -> new_d_number\n",
    "        output_path: Where to save renumbered file (None = overwrite original)\n",
    "    \"\"\"\n",
    "    distances, other_lines = parse_plumed_file(file_path)\n",
    "    \n",
    "    new_distances = []\n",
    "    \n",
    "    for old_d_num, atom1, atom2, label1, label2, old_line in distances:\n",
    "        # Normalize pair for lookup\n",
    "        pair = tuple(sorted([label1, label2]))\n",
    "        new_d_num = canonical_mapping[pair]\n",
    "        \n",
    "        # Reconstruct the line with new d-number\n",
    "        new_line = f\"d{new_d_num}: DISTANCE ATOMS={atom1},{atom2}  # {label1} - {label2}\\n\"\n",
    "        new_distances.append((new_d_num, new_line))\n",
    "    \n",
    "    # Sort by new d-number\n",
    "    new_distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "    if output_path is None:\n",
    "        output_path = file_path\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        for line in other_lines:\n",
    "            if line.strip().startswith('#') or not line.strip():\n",
    "                f.write(line)\n",
    "                if 'Define distances' in line:\n",
    "                    break\n",
    "        \n",
    "        for _, line in new_distances:\n",
    "            f.write(line)\n",
    "        \n",
    "        total_distances = len(new_distances)\n",
    "        if total_distances > 0:\n",
    "            distance_list = ','.join([f\"d{i}\" for i in range(1, total_distances + 1)])\n",
    "            f.write(\"# Print values every 12500 steps, every 25 ps\\n\")\n",
    "            f.write(f\"PRINT FILE=distances STRIDE=12500 ARG={distance_list}\\n\")\n",
    "    \n",
    "    return len(new_distances)\n",
    "\n",
    "def fix_plumed_files(file_paths, create_backup=True):\n",
    "    \"\"\"\n",
    "    Renumber all PLUMED files to have consistent d-number assignments.\n",
    "    \n",
    "    Args:\n",
    "        file_paths: List of file paths to fix\n",
    "        create_backup: If True, create .bak files before modifying\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"PLUMED FILE RENUMBERING SCRIPT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    all_files_data = {}\n",
    "    for path in file_paths:\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"WARNING: File {path} does not exist, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nReading: {path}\")\n",
    "        distances, other_lines = parse_plumed_file(path)\n",
    "        print(f\"  Found {len(distances)} distance definitions\")\n",
    "        all_files_data[path] = (distances, other_lines)\n",
    "    \n",
    "    if not all_files_data:\n",
    "        print(\"\\nERROR: No valid files to process!\")\n",
    "        return\n",
    "    \n",
    "    # Create canonical ordering\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Creating canonical ordering...\")\n",
    "    canonical_mapping = create_canonical_ordering(all_files_data)\n",
    "    print(f\"Total unique pairs: {len(canonical_mapping)}\")\n",
    "    \n",
    "    # For quick checking of outputs \n",
    "    print(\"\\nExample mappings:\")\n",
    "    for i, (pair, d_num) in enumerate(list(canonical_mapping.items())[:5]):\n",
    "        print(f\"  d{d_num}: {pair[0]} - {pair[1]}\")\n",
    "    print(\"  ...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Renumbering files...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for file_path in all_files_data.keys():\n",
    "        if create_backup:\n",
    "            backup_path = file_path + \".bak\"\n",
    "            print(f\"\\nCreating backup: {backup_path}\")\n",
    "            \n",
    "            with open(file_path, 'r') as f_in:\n",
    "                with open(backup_path, 'w') as f_out:\n",
    "                    f_out.write(f_in.read())\n",
    "        \n",
    "        print(f\"Renumbering: {file_path}\")\n",
    "        num_distances = renumber_file(file_path, canonical_mapping)\n",
    "        print(f\"  Wrote {num_distances} renumbered distance definitions\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RENUMBERING COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    if create_backup:\n",
    "        print(\"\\nOriginal files backed up with .bak extension\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    # Filter out Jupyter kernel arguments\n",
    "    filtered_args = [arg for arg in sys.argv[1:] if not arg.startswith('--') and not arg.startswith('-f=')]\n",
    "    \n",
    "    if len(filtered_args) > 0:\n",
    "        file_paths = filtered_args\n",
    "    else:\n",
    "        file_paths = [\n",
    "            \"path/to example/GABA_open/gromacs/distances.dat\",\n",
    "            \"path/to example/Bicuculline_resting/gromacs/distances.dat\",\n",
    "            \"path/to example/Picrotoxin_desensitized/gromacs/distances.dat\"\n",
    "            \"path/to example/Phenobarbital_GABA_open/gromacs/distances.dat\"\n",
    "        ]\n",
    "    # keep backup \n",
    "    fix_plumed_files(file_paths, create_backup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f84fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
